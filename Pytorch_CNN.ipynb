{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import (Dataset, DataLoader, TensorDataset)\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to C:/Users/82109/Desktop/Torch/FashionMNIST\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4587bc83a4f46c1a3caf982a683d638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:/Users/82109/Desktop/Torch/FashionMNIST\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to C:/Users/82109/Desktop/Torch/FashionMNIST\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to C:/Users/82109/Desktop/Torch/FashionMNIST\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "197284ef573f43a5952c01e28dcb7352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:/Users/82109/Desktop/Torch/FashionMNIST\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to C:/Users/82109/Desktop/Torch/FashionMNIST\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to C:/Users/82109/Desktop/Torch/FashionMNIST\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de859ae0076e4d6899c163b4d1f9141a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:/Users/82109/Desktop/Torch/FashionMNIST\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to C:/Users/82109/Desktop/Torch/FashionMNIST\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to C:/Users/82109/Desktop/Torch/FashionMNIST\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6669856773194bb391cc6016c904bd7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:/Users/82109/Desktop/Torch/FashionMNIST\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to C:/Users/82109/Desktop/Torch/FashionMNIST\\FashionMNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82109\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "fashion_mnist_train = FashionMNIST(\"C:/Users/82109/Desktop/Torch/FashionMNIST\",\n",
    "                                  train = False, download = True, transform = transforms.ToTensor())\n",
    "fashion_mnist_test = FashionMNIST(\"C:/Users/82109/Desktop/Torch/FashionMNIST\",\n",
    "                                  train = False, download = True, transform = transforms.ToTensor())\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(fashion_mnist_train,\n",
    "                         batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(fashion_mnist_test,\n",
    "                         batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (N, C, H, W) 형식의 텐서를 (N, C*H*W)로 늘리는 계층\n",
    "# 합성곱 출력을 MLP에 전달할 때 필요\n",
    "class FlattenLayer(nn.Module):\n",
    "    def forward(self, x):\n",
    "        sizes = x.size()\n",
    "        return x.view(sizes[0], -1)\n",
    "    \n",
    "conv_net = nn.Sequential(\n",
    "    nn.Conv2d(1,32,5),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.Dropout2d(0.25),\n",
    "    nn.Conv2d(32,64,5),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.Dropout2d(0.25),\n",
    "    FlattenLayer()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱에 의해 최종적으로 이미지 크기가 어떤지를 더미 데이터를 넣어 확인\n",
    "test_input = torch.ones(1,1,28,28)\n",
    "conv_output_size = conv_net(test_input).size()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2층 MLP\n",
    "\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(conv_output_size, 200),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(200),\n",
    "    nn.Dropout(0.25),\n",
    "    nn.Linear(200,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 CNN\n",
    "net = nn.Sequential(\n",
    "    conv_net,\n",
    "    mlp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가용 헬퍼 함수\n",
    "def eval_net(net, data_loader, device = \"cpu\"):\n",
    "    # Dropout 및 BatchNorm을 무효화\n",
    "    net.eval()\n",
    "    ys = []\n",
    "    ypreds = []\n",
    "    for x, y in data_loader:\n",
    "        # to 메서드로 계산을 실행할 디바이스로 전송\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        # 확률이 가장 큰 분류를 예측\n",
    "        with torch.no_grad():\n",
    "            _, y_pred = net(x).max(1)\n",
    "        ys.append(y)\n",
    "        ypreds.append(y_pred)\n",
    "    # 미니 배치 단위의 예측 결과 등을 하나로 묶는다.\n",
    "    ys = torch.cat(ys)\n",
    "    ypreds = torch.cat(ypreds)\n",
    "    # 예측 정확도 계산\n",
    "    acc = (ys == ypreds).float().sum() / len(ys)\n",
    "    return acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련용 헬퍼 함수\n",
    "def train_net(net, train_loader, test_loader,\n",
    "             optimizer_cls = optim.Adam,\n",
    "             loss_fn = nn.CrossEntropyLoss(),\n",
    "             n_iter = 10, device = \"cpu\"):\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    optimizer = optimizer_cls(net.parameters())\n",
    "    for epoch in range(n_iter):\n",
    "        running_loss = 0.0\n",
    "        # 신경망을 훈련모드로 설정\n",
    "        net.train()\n",
    "        n = 0\n",
    "        n_acc = 0\n",
    "        # tqdm을 사용하여 진행바를 표시\n",
    "        for i, (xx, yy) in tqdm.tqdm(enumerate(train_loader), total = len(train_loader)):\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "            h = net(xx)\n",
    "            loss = loss_fn(h, yy)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            n += len(xx)\n",
    "            _, y_pred = h.max(1)\n",
    "            n_acc += (yy == y_pred).float().sum().item()\n",
    "        train_losses.append(running_loss / i)\n",
    "        train_acc.append(n_acc / n)\n",
    "        val_acc.append(eval_net(net, test_loader, device))\n",
    "        # epoch의 결과 표시\n",
    "        print(epoch, train_losses[-1], train_acc[-1],\n",
    "             val_acc[-1],flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [00:02<00:00, 36.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6850146036117505 0.7544 0.8438000082969666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 110.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.4708318557494726 0.8306 0.8773999810218811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 110.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.4058443181789838 0.8563 0.8983999490737915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 110.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.3563859136058734 0.8717 0.9073999524116516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 110.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.32231664447448194 0.8866 0.9271000027656555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 111.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.2976344896432681 0.8942 0.9314999580383301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 111.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.2864979415749892 0.8958 0.9304999709129333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 110.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.25686689771902865 0.9086 0.9430999755859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 110.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.24105931283571783 0.9136 0.9495999813079834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 109.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.2329454101048983 0.9153 0.9572999477386475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 109.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.21769061101934847 0.9221 0.9580000042915344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 111.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0.20588077050753129 0.9249 0.9634999632835388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 111.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 0.1960415667257248 0.9277 0.9666999578475952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 110.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 0.1802809078914997 0.941 0.971299946308136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 110.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 0.18722105040573156 0.9331 0.9718999862670898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 110.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0.16892059061389703 0.9375 0.9797999858856201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 109.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0.16168748840498617 0.9417 0.9809999465942383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 109.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 0.15618377073835105 0.9421 0.9774999618530273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 109.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 0.14625372904806566 0.9481 0.9764999747276306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 111.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 0.13377916478575805 0.9503 0.9836999773979187\n"
     ]
    }
   ],
   "source": [
    "# 신경망의 모든 파라미터를 GPU로 전송\n",
    "net.to(\"cuda:0\")\n",
    "\n",
    "# 훈련 실행\n",
    "train_net(net, train_loader, test_loader, n_iter = 20, device = \"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 타코와 부리토 분류문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "\n",
    "# ImageFolder 함수를 사용해서 Dataset 작성\n",
    "train_imgs = ImageFolder(\"C:/Users/82109/Desktop/Torch/taco_and_burrito/train/\",\n",
    "                        transform = transforms.Compose([\n",
    "                            transforms.RandomCrop(224), # 224 * 224 크기로 자른다\n",
    "                            transforms.ToTensor()]\n",
    "))\n",
    "\n",
    "test_imgs = ImageFolder(\"C:/Users/82109/Desktop/Torch/taco_and_burrito/test/\",\n",
    "                        transform = transforms.Compose([\n",
    "                            transforms.RandomCrop(224),  \n",
    "                            transforms.ToTensor()]\n",
    "))\n",
    "\n",
    "# DataLoader 작성\n",
    "train_loader = DataLoader(\n",
    "    train_imgs, batch_size = 32, shuffle = True)\n",
    "test_loader = DataLoader(\n",
    "    test_imgs, batch_size = 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['burrito', 'taco']\n",
      "train Classes:{'burrito': 0, 'taco': 1}\n"
     ]
    }
   ],
   "source": [
    "print(train_imgs.classes)\n",
    "print(\"train Classes:{}\".format(train_imgs.class_to_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre-trained Model 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=512, out_features=2, bias=True)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "# resnet18\n",
    "net = models.resnet18(pretrained = True)\n",
    "\n",
    "# 모든 파라미터를 미분 대상에서 제외\n",
    "for p in net.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# 마지막 선형 계층(softmax class)을 변경\n",
    "fc_input_dim = net.fc.in_features\n",
    "net.fc = nn.Linear(fc_input_dim, 2)\n",
    "print(net.fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model의 train function 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net(net, data_loader, device = \"cpu\"):\n",
    "    # Dropout 및 BatchNorm을 무효화\n",
    "    net.eval()\n",
    "    ys = []\n",
    "    ypreds = []\n",
    "    for x, y in data_loader:\n",
    "        # to 메서드로 계산을 실행할 디바이스로 전송\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        # 확률이 가장 큰 분류를 예측\n",
    "        with torch.no_grad():\n",
    "            _, y_pred = net(x).max(1)\n",
    "        ys.append(y)\n",
    "        ypreds.append(y_pred)\n",
    "    # 미니 배치 단위의 예측 결과 등을 하나로 묶는다.\n",
    "    ys = torch.cat(ys)\n",
    "    ypreds = torch.cat(ypreds)\n",
    "    # 예측 정확도 계산\n",
    "    acc = (ys == ypreds).float().sum() / len(ys)\n",
    "    return acc.item()\n",
    "\n",
    "def train_net(net, train_loader, test_loader, only_fc = True,\n",
    "             optimizer_cls = optim.Adam,\n",
    "             loss_fn = nn.CrossEntropyLoss(),\n",
    "             n_iter = 10, device = \"cpu\"):\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    if only_fc:\n",
    "        # 마지막 선형계층의 파라미터만 optimizer에 전달\n",
    "        optimizer = optimizer_cls(net.fc.parameters())\n",
    "    else:\n",
    "        optimizer = optimizer_cls(net.parameters())\n",
    "    for epoch in range(n_iter):\n",
    "        running_loss = 0.0\n",
    "        # 신경망을 훈련모드로 설정\n",
    "        net.train()\n",
    "        n = 0\n",
    "        n_acc = 0\n",
    "        for i, (xx,yy) in tqdm.tqdm(enumerate(train_loader), total = len(train_loader)):\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "            h = net(xx)\n",
    "            loss = loss_fn(h,yy)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            n += len(xx)\n",
    "            _, y_pred = h.max(1)\n",
    "            n_acc += (yy == y_pred).float().sum().item()\n",
    "        train_losses.append(running_loss)\n",
    "        train_acc.append(n_acc / n)\n",
    "        val_acc.append(eval_net(net,test_loader,device))\n",
    "        print(epoch, train_losses[-1],train_acc[-1],val_acc[-1],flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 13.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 16.02640074491501 0.5702247191011236 0.7500000596046448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 13.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 11.921103537082672 0.7668539325842697 0.7666667103767395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 13.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 10.069041669368744 0.8286516853932584 0.8000000715255737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 13.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 9.765137612819672 0.8398876404494382 0.8166667222976685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 13.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 8.59145388007164 0.8412921348314607 0.8000000715255737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 13.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 8.385836645960808 0.8497191011235955 0.8166667222976685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 13.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 8.049712523818016 0.8567415730337079 0.8666667342185974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 8.357675448060036 0.8539325842696629 0.8666667342185974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 7.921481519937515 0.8567415730337079 0.8500000238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 13.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 8.318015709519386 0.8384831460674157 0.8000000715255737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 13.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 7.34906692802906 0.8581460674157303 0.8000000715255737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 13.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 8.41932125389576 0.8356741573033708 0.8166667222976685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 13.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 7.255606532096863 0.8595505617977528 0.8000000715255737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 13.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 6.974714130163193 0.8735955056179775 0.8333333730697632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 13.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 6.725234761834145 0.875 0.8666667342185974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 13.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 7.153794422745705 0.8651685393258427 0.8500000238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 13.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 6.618405848741531 0.8862359550561798 0.8333333730697632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 13.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 6.6876527070999146 0.8862359550561798 0.8166667222976685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 13.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 6.648392736911774 0.8693820224719101 0.8333333730697632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 13.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 6.482852786779404 0.8820224719101124 0.8333333730697632\n"
     ]
    }
   ],
   "source": [
    "net.to(\"cuda:0\")\n",
    "train_net(net, train_loader, test_loader, n_iter = 20, device = \"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
